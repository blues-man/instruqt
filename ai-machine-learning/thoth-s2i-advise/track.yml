slug: ai-machine-learning-thoth-s2i-advise
id: i2raqubknxi1
type: track
title: Thoth S2I build with Advise on OpenShift
description: |-
  In this tutorial, we are going to build a simple Python app, using Thoth s2i.
  Thus getting intelligent recommendation on the software stack during the build process.

  ## Why to use Thoth s2i build process?

  For those who are new to this [Source-to-Image(s2i)](https://docs.openshift.com/container-platform/latest/openshift_images/using_images/using-s21-images.html) refers to the Source to image process which
  bundles your source code to a image that can be run on OpenShift.

  So when you use, Thoth s2i build process instead of the normal s2i build process,
  Thoth produces recommendations targeting your specific hardware configuration you
  use to run your application inside the cluster (e.g. specific GPU available in
  the cluster).

  You can find a list of base images which you can use with Thoth in [s2i-thoth repository](https://github.com/thoth-station/s2i-thoth)
  with detailed instructions on how to use Thoth in the OpenShift’s s2i process.
  The container images are hosted at -
  [quay.io](quay.io/organization/thoth-station) with the
  prefix s2i.

  We are going to discover more about it in the next step how you can customize the process.

  In this demo, we are going to use an Openshift 4.7 playground.<br>
  We are operating our services on the MassOpen.cloud [#operatefirst](https://massopen.cloud/connected-initiatives/operate-first)
icon: https://logodix.com/logo/1910931.png
level: intermediate
tags:
- openshift
owner: openshift
developers:
- nvinto@redhat.com
- rjarvine@redhat.com
- mcostant@redhat.com
private: false
published: true
challenges:
- slug: setup
  id: nyhdkkmqfndq
  type: challenge
  title: Getting Started
  notes:
  - type: text
    contents: |-
      In this tutorial, we are going to build a simple Python app, using Thoth s2i.
      Thus getting intelligent recommendation on the software stack during the build process.

      ## Why to use Thoth s2i build process?

      For those who are new to this [Source-to-Image(s2i)](https://docs.openshift.com/container-platform/latest/openshift_images/using_images/using-s21-images.html) refers to the Source to image process which
      bundles your source code to a image that can be run on OpenShift.

      So when you use, Thoth s2i build process instead of the normal s2i build process,
      Thoth produces recommendations targeting your specific hardware configuration you
      use to run your application inside the cluster (e.g. specific GPU available in
      the cluster).

      You can find a list of base images which you can use with Thoth in [s2i-thoth repository](https://github.com/thoth-station/s2i-thoth)
      with detailed instructions on how to use Thoth in the OpenShift’s s2i process.
      The container images are hosted at -
      [quay.io](quay.io/organization/thoth-station) with the
      prefix s2i.

      We are going to discover more about it in the next step how you can customize the process.

      In this demo, we are going to use an Openshift 4.7 playground.<br>
      We are operating our services on the MassOpen.cloud [#operatefirst](https://massopen.cloud/connected-initiatives/operate-first)
  assignment: |-
    Before you get started we recommend reading the following steps. They explain
    a bit about how the playground environment is setup and what access you have.

    ## Logging in to the Cluster via Dashboard

    Click the [Console](https://console-openshift-console-[[HOST_SUBDOMAIN]]-443-[[KATACODA_HOST]].environments.katacoda.com) tab to open the dashboard.

    You will then able able to login with admin permissions with:

    * **Username:** ``developer``
    * **Password:** ``developer``

    ## Logging in to the Cluster via CLI

    When the OpenShift playground is created you will be logged in initially as
    a cluster admin (`oc whoami`) on the command line. This will allow you to perform
    operations which would normally be performed by a cluster admin.

    Before creating any applications, it is recommended you login as a distinct
    user. This will be required if you want to log in to the web console and
    use it.

    To login to the OpenShift cluster from the _Terminal_ run:

    ```
    oc login -u developer -p developer
    ```

    This will log you in using the credentials:

    * **Username:** ``developer``
    * **Password:** ``developer``

    Use the same credentials to log into the web console.
    For simplicity we are logging in here as admin.

    ## Creating your own Project

    To create a new project called ``myproject`` run the command:

    ```
    oc new-project myproject
    ```

    You could instead create the project from the web console. If you do this,
    to change to the project from the command line run the command:

    ```
    oc project myproject
    ```

    Now that you have created your own project, me move to the next
    step.
  tabs:
  - title: Terminal 1
    type: terminal
    hostname: crc
  - title: Visual Editor
    type: code
    hostname: crc
    path: /root
  - title: Web Console
    type: website
    url: https://console-openshift-console.crc-5nvrm-master-0.crc.${_SANDBOX_ID}.instruqt.io
    new_window: true
  difficulty: intermediate
  timelimit: 150
- slug: app
  id: ot5kvp3syaxx
  type: challenge
  title: Getting the sample Python app
  assignment: |-
    Before we explore more about the build process, let's check the sample repo we have for the demo,
    and explore more about the s2i process.

    Here is the example repo we are going to try today -

    [https://github.com/thoth-station/s2i-example](https://github.com/thoth-station/s2i-example)

    Now let's check out the `log-thoth` branch.
    The upstream link to the same is - [https://github.com/thoth-station/s2i-example/tree/log-thoth](https://github.com/thoth-station/s2i-example/tree/log-thoth)

    If you go to app.py, it's a simple Python app that prints `Hello thoth` every 10 seconds.
    And you have a Pipfile that has `daiquiri` as the only package. That is the standard python project, we are going to experiment with.

    Now let's explore the `openshift.yaml`.
    End of the yaml, we declare the image to be `s2i-thoth-ubi8-py38`
    ```
      - apiVersion: "image.openshift.io/v1"
        kind: ImageStream
        metadata:
          labels:
            app: "s2i-example-log"
          name: "s2i-thoth-ubi8-py38"
        spec:
          tags:
            - name: "latest"
              from:
                kind: "DockerImage"
                name: "quay.io/thoth-station/s2i-thoth-ubi8-py38"
              referencePolicy:
                type: "Source"
    ```
    And we use this under BuildConfig under line 26, stating our source repo to be -
    ```
    git:
        uri: "https://github.com/thoth-station/s2i-example"
        ref: "log-thoth"
    ```
    You could change this to point to your repo fork.
    Now that we have successfully explored the repo, and are using a Thoth powered s2i image, let's explore some configuration options, that
    thoth image provides out of box.
  tabs:
  - title: Terminal 1
    type: terminal
    hostname: crc
  - title: Visual Editor
    type: code
    hostname: crc
    path: /root
  - title: Web Console
    type: website
    url: https://console-openshift-console.crc-5nvrm-master-0.crc.${_SANDBOX_ID}.instruqt.io
    new_window: true
  difficulty: intermediate
  timelimit: 150
- slug: parameter
  id: dcyic0uje3vh
  type: challenge
  title: Thoth s2i parameters
  assignment: |-
    Now finally let's explore the options Thoth s2i build image offers -

    Thoth’s s2i container images can be configured using environment variables supplied to the build config:

    `THOTH_ADVISE` - always use the recommended stack by Thoth (even if Pipfile.lock is present in the repo)

    `THOTH_PROVENANCE_CHECK` - verify stack provenance - the provenance check is triggered only if the lock file is not comming from Thoth’s recommendation engine (otherwise the stack has already verified provenance)

    `THOTH_ASSEMBLE_DEBUG` - run s2i’s assemble script in verbose mode

    `THOTH_DRY_RUN` - submit stack to Thoth’s recommendation engine but do not use the recommended Pipfile.lock file, use the Pipfile.lock file present in the repo instead

    `THOTH_FROM_MASTER` - Use Thamos from git instead of a PyPI release - handy if the released Thamos has a bug which was fixed in the master branch

    `THOTH_HOST` - Thoth’s host to reach out to for recommendations (defaults to prod deployment at khemenu.thoth-station.ninja)

    `THOTH_ERROR_FALLBACK` - fallback to the Pipfile.lock present in the repository if the submitted Thoth analysis fails

    If you go checkout the `openshift.yaml` and checkout the env block under BuildConfig (ln 57), you will see some of these being used like `THAMOS_ADVISE`, `THOTH_DRY_RUN`, `THOTH_HOST`.
    Thamos Host is currently set to `api.moc.thoth-station.ninja`, which is our public facing api.
    And `THAMOS_ADVISE` set to 1, that uses the stack recommended, this would allow us
    to use to Thoth recommended build in the s2i build process.
    For this tutorial we are going to focus on `THAMOS_ADVISE`, hence provenance check is set to 0.


    Here are some config option's that you could configure, which
    changes the behaviour of `THAMOS` (the cli tool used to interact with Thoth internally.)
     - https://thoth-station.ninja/docs/developers/thamos/

    You can see them being used in the sample `openshift.yaml` in your repo, feel free to try tinkering with them according to your need.
  tabs:
  - title: Terminal 1
    type: terminal
    hostname: crc
  - title: Visual Editor
    type: code
    hostname: crc
    path: /root
  - title: Web Console
    type: website
    url: https://console-openshift-console.crc-5nvrm-master-0.crc.${_SANDBOX_ID}.instruqt.io
    new_window: true
  difficulty: intermediate
  timelimit: 150
- slug: deploy
  id: qdsm2jaz1inh
  type: challenge
  title: Let's Deploy
  assignment: |-
    Now that you are familiar with the configurations our s2i image offers, let's try deploying our sample app using Thoth's S2I build process.

    Assuming you have followed the steps from before and are logged in as an admin into `myproject` in the openshift cluster lets deploy -

    You can try deploying our version using -

    ```
    oc process -f https://raw.githubusercontent.com/thoth-station/s2i-example/log-thoth/openshift.yaml | oc apply -f -
    ```




    Now that you have scheduled it in the katacoda terminal on the right, you should see this -
    ```
    buildconfig.build.openshift.io/s2i-example-log created
    deploymentconfig.apps.openshift.io/s2i-example-log created
    imagestream.image.openshift.io/s2i-example-log created
    imagestream.image.openshift.io/s2i-thoth-ubi8-py38 created
    ```

    ### Let's go to Openshift UI and checkout our build process -

    Make sure you have selected `myproject` on the project selector.
    If you go to Builds in the Openshift UI in the other tab, under `Builds`, you would see `s2i-example-log` and under logs you could inspect the build process.
    You would see `thamos advise` being run on your stack and if there is a suggestion.
    Incase the analysis fails, we resort to the existing Pipfile.lock to prevent the build from failing.

    Now lets check the logs -

    ```
    oc logs bc/s2i-example-log -f
    ```

    You should keep a eye for these things in the log -
     - Thoth's configuration file after hardware and software discovery (that's the .thoth.yaml being expanded from the template.)
     - Asking Thoth for advise... (That is where thamos interacts with Thoth API)

    Now if you check the UI, your app should be running under `Workloads -> Pods`.

    Once the application is deployed, you can check the logs from the deployed app using -

    ```
    oc logs -f bc/s2i-example-log
    ```

    After Thoth finishes processing your stack you should see something similar to this in your report -
    ![thoth advise pass](https://raw.githubusercontent.com/saisankargochhayat/katacoda-scenarios/master/hello-world/assets/thamos_advise_pass.png)

    If you want to remove the app from the cluster -

    ```
    oc delete all --selector 'app=s2i-example-log'
    ```
  tabs:
  - title: Terminal 1
    type: terminal
    hostname: crc
  - title: Visual Editor
    type: code
    hostname: crc
    path: /root
  - title: Web Console
    type: website
    url: https://console-openshift-console.crc-5nvrm-master-0.crc.${_SANDBOX_ID}.instruqt.io
    new_window: true
  difficulty: intermediate
  timelimit: 300
checksum: "17802469700334139941"
